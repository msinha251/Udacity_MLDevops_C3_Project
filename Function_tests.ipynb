{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "709164b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Using cached google_api_python_client-2.64.0-py2.py3-none-any.whl (10.4 MB)\n",
      "Collecting google-auth-httplib2\n",
      "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-auth-oauthlib\n",
      "  Using cached google_auth_oauthlib-0.5.3-py2.py3-none-any.whl (19 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Using cached google_api_core-2.10.2-py3-none-any.whl (115 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Using cached httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "Collecting google-auth<3.0.0dev,>=1.19.0\n",
      "  Using cached google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
      "Requirement already satisfied: six in /Users/mahesh.sinha/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages (from google-auth-httplib2) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Using cached googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5\n",
      "  Using cached protobuf-4.21.7-cp37-abi3-macosx_10_9_universal2.whl (484 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/mahesh.sinha/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/mahesh.sinha/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/mahesh.sinha/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mahesh.sinha/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/mahesh.sinha/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mahesh.sinha/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mahesh.sinha/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.11)\n",
      "Installing collected packages: pyasn1, uritemplate, rsa, pyasn1-modules, protobuf, httplib2, cachetools, requests-oauthlib, googleapis-common-protos, google-auth, google-auth-oauthlib, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "wandb 0.13.1 requires protobuf<4.0dev,>=3.12.0, but you have protobuf 4.21.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cachetools-5.2.0 google-api-core-2.10.2 google-api-python-client-2.64.0 google-auth-2.12.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.5.3 googleapis-common-protos-1.56.4 httplib2-0.20.4 protobuf-4.21.7 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b7f3cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Client secrets must be for a web or installed app.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m main()\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     creds\u001b[38;5;241m.\u001b[39mrefresh(Request())\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     flow \u001b[38;5;241m=\u001b[39m \u001b[43mInstalledAppFlow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_client_secrets_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcredentials.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCOPES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     creds \u001b[38;5;241m=\u001b[39m flow\u001b[38;5;241m.\u001b[39mrun_local_server(port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Save the credentials for the next run\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages/google_auth_oauthlib/flow.py:207\u001b[0m, in \u001b[0;36mFlow.from_client_secrets_file\u001b[0;34m(cls, client_secrets_file, scopes, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(client_secrets_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m    205\u001b[0m     client_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_client_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/udacity-ml-devops-nano-2/lib/python3.8/site-packages/google_auth_oauthlib/flow.py:165\u001b[0m, in \u001b[0;36mFlow.from_client_config\u001b[0;34m(cls, client_config, scopes, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     client_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstalled\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient secrets must be for a web or installed app.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# these args cannot be passed to requests_oauthlib.OAuth2Session\u001b[39;00m\n\u001b[1;32m    168\u001b[0m code_verifier \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_verifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Client secrets must be for a web or installed app."
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Shows basic usage of the Drive v3 API.\n",
    "    Prints the names and ids of the first 10 files the user has access to.\n",
    "    \"\"\"\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    try:\n",
    "        service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "        # Call the Drive v3 API\n",
    "        results = service.files().list(\n",
    "            pageSize=10, fields=\"nextPageToken, files(id, name)\").execute()\n",
    "        items = results.get('files', [])\n",
    "\n",
    "        if not items:\n",
    "            print('No files found.')\n",
    "            return\n",
    "        print('Files:')\n",
    "        for item in items:\n",
    "            print(u'{0} ({1})'.format(item['name'], item['id']))\n",
    "    except HttpError as error:\n",
    "        # TODO(developer) - Handle errors from drive API.\n",
    "        print(f'An error occurred: {error}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c33a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f494baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to the Adult Income Prediction API'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('http://localhost:8000/')\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bea6cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "The predicted income is: >50k\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "sample_dict = {     \n",
    "                    \"workclass\": \"state_gov\",\n",
    "                    \"education\": \"bachelors\",\n",
    "                    \"marital_status\": \"never_married\",\n",
    "                    \"occupation\": \"adm_clerical\",\n",
    "                    \"relationship\": \"not_in_family\",\n",
    "                    \"race\": \"white\",\n",
    "                    \"sex\": \"male\",\n",
    "                    \"native_country\": \"united_states\",\n",
    "                    \"age\": 39,\n",
    "                    \"fnlwgt\": 77516,\n",
    "                    \"education_num\": 13,\n",
    "                    \"capital_gain\": 10000,\n",
    "                    \"capital_loss\": 0,\n",
    "                    \"hours_per_week\": 40\n",
    "                }\n",
    "response = requests.post('http://localhost:8000/predict', json=sample_dict)\n",
    "print(response)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39b88e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [422]>\n",
      "Please enter all the data\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "sample_dict = {\n",
    "                    \"workclass\": \"string\",\n",
    "                    \"education\": \"string\",\n",
    "                    \"marital_status\": \"string\",\n",
    "                    \"occupation\": \"string\",\n",
    "                    \"relationship\": \"string\",\n",
    "                    \"race\": \"string\",\n",
    "                    \"sex\": \"string\",\n",
    "                    \"native_country\": \"string\",\n",
    "                    \"age\": 10,\n",
    "                    \"fnlwgt\": 10,\n",
    "                    \"education_num\": 10,\n",
    "                    \"capital_gain\": 10,\n",
    "                    \"capital_loss\": 10,\n",
    "                    \"hours_per_week\": 10\n",
    "                }\n",
    "response = requests.post('http://localhost:8000/predict', json=sample_dict)\n",
    "print(response)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0cd4c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(sample_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6749f207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(list(sample_dict.values())) == \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096d469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5948bf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracting columns from adult.names\n",
      "INFO:root:Columns: ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
      "INFO:root:Train data shape: (32561, 15)\n",
      "INFO:root:Test data shape: (16281, 15)\n",
      "INFO:root:Train target counts: 0    24720\n",
      "1     7841\n",
      "Name: earn_over_50k, dtype: int64\n",
      "INFO:root:Test target counts: 0    12435\n",
      "1     3846\n",
      "Name: earn_over_50k, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from operator import mod\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "#logging:\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    '''\n",
    "    Load data from data_path\n",
    "    '''\n",
    "    #extracting columns from adult.names\n",
    "    cols = []\n",
    "    logging.info(f'Extracting columns from adult.names')\n",
    "    with open(f'{data_path}/adult.names', 'r') as names:\n",
    "        for line in names:\n",
    "            if ':' in line and '|' not in line:\n",
    "                cols.append(line.split(':')[0])\n",
    "    logging.info(f'Columns: {cols}')\n",
    "\n",
    "    #load train data:\n",
    "    df_train = pd.read_csv(f'{data_path}/adult.data', names=cols+['earn_over_50k'], index_col=False)\n",
    "    logging.info(f'Train data shape: {df_train.shape}')\n",
    "    #load test data:\n",
    "    df_test = pd.read_csv(f'{data_path}/adult.test', names=cols+['earn_over_50k'], index_col=False, skiprows=[0])\n",
    "    logging.info(f'Test data shape: {df_test.shape}')\n",
    "\n",
    "    #convert train target to 0/1:\n",
    "    df_train['earn_over_50k'] = df_train['earn_over_50k'].apply(lambda x: 1 if x == ' >50K' else 0)\n",
    "    logging.info(f'Train target counts: {df_train[\"earn_over_50k\"].value_counts()}')\n",
    "    #convert test target to 0/1:\n",
    "    df_test['earn_over_50k'] = df_test['earn_over_50k'].apply(lambda x: 1 if x == ' >50K.' else 0)\n",
    "    logging.info(f'Test target counts: {df_test[\"earn_over_50k\"].value_counts()}')\n",
    "\n",
    "    return df_train, df_test\n",
    "df_train, df_test = load_data('./data')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dcd211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Columns: Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'earn_over_50k'],\n",
      "      dtype='object')\n",
      "INFO:root:Categorical columns: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "INFO:root:Numerical columns: ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week', 'earn_over_50k']\n",
      "INFO:root:Before replacing ? with nan: age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education_num        0\n",
      "marital_status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital_gain         0\n",
      "capital_loss         0\n",
      "hours_per_week       0\n",
      "native_country     583\n",
      "earn_over_50k        0\n",
      "dtype: int64\n",
      "/var/folders/_2/sdzrwz45427b53fcr8rggplm0000gq/T/ipykernel_23078/896542310.py:21: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df = df.replace('?', pd.np.nan)\n",
      "INFO:root:Nan values: age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education_num        0\n",
      "marital_status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital_gain         0\n",
      "capital_loss         0\n",
      "hours_per_week       0\n",
      "native_country     583\n",
      "earn_over_50k        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def basic_cleaning(df):\n",
    "    '''\n",
    "    Basic cleaning of data-\n",
    "    '''\n",
    "    #fixing column names:\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "    logging.info(f'Columns: {df.columns}')\n",
    "\n",
    "    #filter categorical columns and numerical columns:\n",
    "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    num_cols = df.select_dtypes(exclude='object').columns.tolist()\n",
    "    logging.info(f'Categorical columns: {cat_cols}')\n",
    "    logging.info(f'Numerical columns: {num_cols}')\n",
    "    \n",
    "     #replacing spaces & - with underscore in categorical columns:\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "\n",
    "    #replacing ? with nan:\n",
    "    logging.info(f'Before replacing ? with nan: {df.isin([\"?\"]).sum()}')\n",
    "    df = df.replace('?', pd.np.nan)\n",
    "    logging.info(f'Nan values: {df.isna().sum()}')\n",
    "\n",
    "    #fill nan with mode for categorical columns:\n",
    "    for col in cat_cols:\n",
    "        if col != 'earn_over_50k':\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            cat_cols.remove(col)\n",
    "\n",
    "    #fill nan with mean for numerical columns:\n",
    "    for col in num_cols:\n",
    "        if col != 'earn_over_50k':\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        else:\n",
    "            num_cols.remove(col)\n",
    "\n",
    "    return df, cat_cols + num_cols\n",
    "\n",
    "train, cols = basic_cleaning(df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eff7cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b57548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e00bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training model on Columns: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country', 'age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
      "INFO:root:Fold: 0\n",
      "INFO:root:Fold: 0, Score: 0.6054567805126353\n",
      "INFO:root:Fold: 1\n",
      "INFO:root:Fold: 1, Score: 0.5685005439845257\n",
      "INFO:root:Fold: 2\n",
      "INFO:root:Fold: 2, Score: 0.5731820109718645\n",
      "INFO:root:Fold: 3\n",
      "INFO:root:Fold: 3, Score: 0.6043548070771081\n",
      "INFO:root:Fold: 4\n",
      "INFO:root:Fold: 4, Score: 0.58933937652731\n",
      "INFO:root:Mean Score: 0.5881667038146887\n"
     ]
    }
   ],
   "source": [
    "def train_model(df_train, cols):\n",
    "    '''\n",
    "    Trains model on train data\n",
    "    '''\n",
    "    logging.info(f'Training model on Columns: {cols}')\n",
    "    \n",
    "    #Initialize KFold:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    fold = 0\n",
    "    for train_index, val_index in kf.split(df_train):\n",
    "        logging.info(f'Fold: {fold}')\n",
    "\n",
    "        #create train dict:\n",
    "        train_dict = df_train[cols].iloc[train_index].to_dict(orient='records')\n",
    "        \n",
    "        #create val dict:\n",
    "        val_dict = df_train[cols].iloc[val_index].to_dict(orient='records')\n",
    "        \n",
    "        #create train target:\n",
    "        train_target = df_train['earn_over_50k'].iloc[train_index]\n",
    "\n",
    "        #create val target:\n",
    "        val_target = df_train['earn_over_50k'].iloc[val_index]\n",
    "\n",
    "        #initialize DictVectorizer:\n",
    "        dv = DictVectorizer(sparse=False)\n",
    "\n",
    "        #fit DictVectorizer on train dict:\n",
    "        dv.fit(train_dict)\n",
    "\n",
    "        #transform train dict:\n",
    "        X_train = dv.transform(train_dict)\n",
    "\n",
    "        #transform val dict:\n",
    "        X_val = dv.transform(val_dict)\n",
    "\n",
    "        #initialize & fit LogisticRegression:\n",
    "        model = LogisticRegression(solver='liblinear', C=1.0, random_state=42)\n",
    "        model.fit(X_train, train_target)\n",
    "\n",
    "        #predict on val data:\n",
    "        y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        #calculate roc_auc_score:\n",
    "        score = roc_auc_score(val_target, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "        logging.info(f'Fold: {fold}, Score: {score}')\n",
    "        fold += 1\n",
    "\n",
    "    logging.info(f'Mean Score: {np.mean(scores)}')\n",
    "\n",
    "    return dv, model\n",
    "\n",
    "dv, model = train_model(train, cols)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c69d2b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "dv = DictVectorizer()\n",
    "train_dict = train[cols].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "y_train = train.earn_over_50k.values\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46a37397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5478402179858726"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_single(sample_dict, dv, model):\n",
    "    '''\n",
    "    Predicts on single row of test data\n",
    "    Sample input:\n",
    "    {   'workclass': 'state_gov',\n",
    "        'education': 'bachelors',\n",
    "        'marital_status': 'never_married',\n",
    "        'occupation': 'adm_clerical',\n",
    "        'relationship': 'not_in_family',\n",
    "        'race': 'white',\n",
    "        'sex': 'male',\n",
    "        'native_country': 'united_states',\n",
    "        'age': 39,\n",
    "        'fnlwgt': 77516,\n",
    "        'education_num': 13,\n",
    "        'capital_gain': 2174,\n",
    "        'capital_loss': 0,\n",
    "        'hours_per_week': 40\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    #transform test dict:\n",
    "    X_test = dv.transform(sample_dict)\n",
    "\n",
    "    #predict on test data:\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return y_pred[0]\n",
    "\n",
    "sample_dict = {     'workclass': 'state_gov',\n",
    "                    'education': 'bachelors',\n",
    "                    'marital_status': 'never_married',\n",
    "                    'occupation': 'adm_clerical',\n",
    "                    'relationship': 'not_in_family',\n",
    "                    'race': 'white',\n",
    "                    'sex': 'male',\n",
    "                    'native_country': 'united_states',\n",
    "                    'age': 39,\n",
    "                    'fnlwgt': 77516,\n",
    "                    'education_num': 13,\n",
    "                    'capital_gain': 2174,\n",
    "                    'capital_loss': 0,\n",
    "                    'hours_per_week': 40\n",
    "                }\n",
    "\n",
    "predict_single(sample_dict, dv, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "224f331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Columns: Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'earn_over_50k'],\n",
      "      dtype='object')\n",
      "INFO:root:Categorical columns: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "INFO:root:Numerical columns: ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week', 'earn_over_50k']\n",
      "INFO:root:Before replacing ? with nan: age                 0\n",
      "workclass         963\n",
      "fnlwgt              0\n",
      "education           0\n",
      "education_num       0\n",
      "marital_status      0\n",
      "occupation        966\n",
      "relationship        0\n",
      "race                0\n",
      "sex                 0\n",
      "capital_gain        0\n",
      "capital_loss        0\n",
      "hours_per_week      0\n",
      "native_country    274\n",
      "earn_over_50k       0\n",
      "dtype: int64\n",
      "/var/folders/_2/sdzrwz45427b53fcr8rggplm0000gq/T/ipykernel_23078/896542310.py:21: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df = df.replace('?', pd.np.nan)\n",
      "INFO:root:Nan values: age                 0\n",
      "workclass         963\n",
      "fnlwgt              0\n",
      "education           0\n",
      "education_num       0\n",
      "marital_status      0\n",
      "occupation        966\n",
      "relationship        0\n",
      "race                0\n",
      "sex                 0\n",
      "capital_gain        0\n",
      "capital_loss        0\n",
      "hours_per_week      0\n",
      "native_country    274\n",
      "earn_over_50k       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test, cols = basic_cleaning(df_test)\n",
    "\n",
    "def predict_batch(df_test, dv, model, cols):\n",
    "    '''\n",
    "    Predicts on test data\n",
    "    '''\n",
    "    #create test dict:\n",
    "    test_dict = df_test[cols].to_dict(orient='records')\n",
    "\n",
    "    #transform test dict:\n",
    "    X_test = dv.transform(test_dict)\n",
    "    X_test[0]\n",
    "\n",
    "    #predict on test data:\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred = predict_batch(test, dv, model, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2b51ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Score on test data: 0.6196447109995377\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'Score on test data: {roc_auc_score(df_test.earn_over_50k, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "796cd811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>earn_over_50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass  fnlwgt      education  education-num  \\\n",
       "0       25        Private  226802           11th              7   \n",
       "1       38        Private   89814        HS-grad              9   \n",
       "2       28      Local-gov  336951     Assoc-acdm             12   \n",
       "3       44        Private  160323   Some-college             10   \n",
       "4       18              ?  103497   Some-college             10   \n",
       "...    ...            ...     ...            ...            ...   \n",
       "16276   39        Private  215419      Bachelors             13   \n",
       "16277   64              ?  321403        HS-grad              9   \n",
       "16278   38        Private  374983      Bachelors             13   \n",
       "16279   44        Private   83891      Bachelors             13   \n",
       "16280   35   Self-emp-inc  182148      Bachelors             13   \n",
       "\n",
       "            marital-status          occupation     relationship  \\\n",
       "0            Never-married   Machine-op-inspct        Own-child   \n",
       "1       Married-civ-spouse     Farming-fishing          Husband   \n",
       "2       Married-civ-spouse     Protective-serv          Husband   \n",
       "3       Married-civ-spouse   Machine-op-inspct          Husband   \n",
       "4            Never-married                   ?        Own-child   \n",
       "...                    ...                 ...              ...   \n",
       "16276             Divorced      Prof-specialty    Not-in-family   \n",
       "16277              Widowed                   ?   Other-relative   \n",
       "16278   Married-civ-spouse      Prof-specialty          Husband   \n",
       "16279             Divorced        Adm-clerical        Own-child   \n",
       "16280   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital-gain  capital-loss  \\\n",
       "0                    Black     Male             0             0   \n",
       "1                    White     Male             0             0   \n",
       "2                    White     Male             0             0   \n",
       "3                    Black     Male          7688             0   \n",
       "4                    White   Female             0             0   \n",
       "...                    ...      ...           ...           ...   \n",
       "16276                White   Female             0             0   \n",
       "16277                Black     Male             0             0   \n",
       "16278                White     Male             0             0   \n",
       "16279   Asian-Pac-Islander     Male          5455             0   \n",
       "16280                White     Male             0             0   \n",
       "\n",
       "       hours-per-week  native-country  earn_over_50k  \n",
       "0                  40   United-States              0  \n",
       "1                  50   United-States              0  \n",
       "2                  40   United-States              1  \n",
       "3                  40   United-States              1  \n",
       "4                  30   United-States              0  \n",
       "...               ...             ...            ...  \n",
       "16276              36   United-States              0  \n",
       "16277              40   United-States              0  \n",
       "16278              50   United-States              0  \n",
       "16279              40   United-States              0  \n",
       "16280              60   United-States              1  \n",
       "\n",
       "[16281 rows x 15 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9250089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(dv, model, model_path):\n",
    "    '''\n",
    "    Save model to model_path\n",
    "    '''\n",
    "    #save DictVectorizer:\n",
    "    with open(f'{model_path}/dv.bin', 'wb') as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "        f_out.close()\n",
    "    logging.info(f'DictVectorizer saved')\n",
    "\n",
    "    #save model:\n",
    "    with open(f'{model_path}/model1.bin', 'wb') as f_out:\n",
    "        pickle.dump(model, f_out)\n",
    "        f_out.close()\n",
    "    logging.info(f'Model saved')\n",
    "\n",
    "def predict(df_test, dv, model, cols):\n",
    "    '''\n",
    "    Predicts on test data\n",
    "    '''\n",
    "    #create test dict:\n",
    "    test_dict = df_test[cols].to_dict(orient='records')\n",
    "\n",
    "    #transform test dict:\n",
    "    X_test = dv.transform(test_dict)\n",
    "\n",
    "    #predict on test data:\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #load data:\n",
    "    df_train, df_test = load_data('./data')\n",
    "    #clean data:\n",
    "    df_train, cols = basic_cleaning(df_train)\n",
    "    df_test, _ = basic_cleaning(df_test)\n",
    "    logging.info(f'Train data shape: {df_train.shape}')\n",
    "\n",
    "    #train model:\n",
    "    dv, model = train_model(df_train, cols)\n",
    "\n",
    "    #predict on test data:\n",
    "    y_pred = predict(df_test, dv, model, cols)\n",
    "    \n",
    "    #save predictions:\n",
    "    df_test['earn_over_50k'] = y_pred\n",
    "    df_test[['earn_over_50k']].to_csv('./data/predictions.csv', index=False)\n",
    "    logging.info(f'Predictions saved')\n",
    "\n",
    "    #save model:\n",
    "    save_model(dv, model, './model')\n",
    "\n",
    "    logging.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966b54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc2a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction_proba': 0.5279585459636567,\n",
       " 'prediction': 1,\n",
       " 'message': 'Income <=50K'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a7a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475b82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a5c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd5150a16d85c014e5d4927b8ac75bae8a55a545327dd7f7547976b47ce2a268"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
