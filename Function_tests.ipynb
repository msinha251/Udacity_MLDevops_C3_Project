{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8926f04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to the Adult Income Prediction API'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('http://localhost:8000/')\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e96d6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "The predicted income is: >50k\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "sample_dict = {     \n",
    "                    \"workclass\": \"state_gov\",\n",
    "                    \"education\": \"bachelors\",\n",
    "                    \"marital_status\": \"never_married\",\n",
    "                    \"occupation\": \"adm_clerical\",\n",
    "                    \"relationship\": \"not_in_family\",\n",
    "                    \"race\": \"white\",\n",
    "                    \"sex\": \"male\",\n",
    "                    \"native_country\": \"united_states\",\n",
    "                    \"age\": 39,\n",
    "                    \"fnlwgt\": 77516,\n",
    "                    \"education_num\": 13,\n",
    "                    \"capital_gain\": 10000,\n",
    "                    \"capital_loss\": 0,\n",
    "                    \"hours_per_week\": 40\n",
    "                }\n",
    "response = requests.post('http://localhost:8000/predict', json=sample_dict)\n",
    "print(response)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84d899bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [422]>\n",
      "Please enter all the data\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "sample_dict = {\n",
    "                    \"workclass\": \"string\",\n",
    "                    \"education\": \"string\",\n",
    "                    \"marital_status\": \"string\",\n",
    "                    \"occupation\": \"string\",\n",
    "                    \"relationship\": \"string\",\n",
    "                    \"race\": \"string\",\n",
    "                    \"sex\": \"string\",\n",
    "                    \"native_country\": \"string\",\n",
    "                    \"age\": 10,\n",
    "                    \"fnlwgt\": 10,\n",
    "                    \"education_num\": 10,\n",
    "                    \"capital_gain\": 10,\n",
    "                    \"capital_loss\": 10,\n",
    "                    \"hours_per_week\": 10\n",
    "                }\n",
    "response = requests.post('http://localhost:8000/predict', json=sample_dict)\n",
    "print(response)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cca8394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 'string',\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(sample_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4723901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(list(sample_dict.values())) == \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cd7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5948bf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracting columns from adult.names\n",
      "INFO:root:Columns: ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
      "INFO:root:Train data shape: (32561, 15)\n",
      "INFO:root:Test data shape: (16281, 15)\n",
      "INFO:root:Train target counts: 0    24720\n",
      "1     7841\n",
      "Name: earn_over_50k, dtype: int64\n",
      "INFO:root:Test target counts: 0    12435\n",
      "1     3846\n",
      "Name: earn_over_50k, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from operator import mod\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "#logging:\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    '''\n",
    "    Load data from data_path\n",
    "    '''\n",
    "    #extracting columns from adult.names\n",
    "    cols = []\n",
    "    logging.info(f'Extracting columns from adult.names')\n",
    "    with open(f'{data_path}/adult.names', 'r') as names:\n",
    "        for line in names:\n",
    "            if ':' in line and '|' not in line:\n",
    "                cols.append(line.split(':')[0])\n",
    "    logging.info(f'Columns: {cols}')\n",
    "\n",
    "    #load train data:\n",
    "    df_train = pd.read_csv(f'{data_path}/adult.data', names=cols+['earn_over_50k'], index_col=False)\n",
    "    logging.info(f'Train data shape: {df_train.shape}')\n",
    "    #load test data:\n",
    "    df_test = pd.read_csv(f'{data_path}/adult.test', names=cols+['earn_over_50k'], index_col=False, skiprows=[0])\n",
    "    logging.info(f'Test data shape: {df_test.shape}')\n",
    "\n",
    "    #convert train target to 0/1:\n",
    "    df_train['earn_over_50k'] = df_train['earn_over_50k'].apply(lambda x: 1 if x == ' >50K' else 0)\n",
    "    logging.info(f'Train target counts: {df_train[\"earn_over_50k\"].value_counts()}')\n",
    "    #convert test target to 0/1:\n",
    "    df_test['earn_over_50k'] = df_test['earn_over_50k'].apply(lambda x: 1 if x == ' >50K.' else 0)\n",
    "    logging.info(f'Test target counts: {df_test[\"earn_over_50k\"].value_counts()}')\n",
    "\n",
    "    return df_train, df_test\n",
    "df_train, df_test = load_data('./data')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dcd211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Columns: Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'earn_over_50k'],\n",
      "      dtype='object')\n",
      "INFO:root:Categorical columns: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "INFO:root:Numerical columns: ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week', 'earn_over_50k']\n",
      "INFO:root:Before replacing ? with nan: age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education_num        0\n",
      "marital_status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital_gain         0\n",
      "capital_loss         0\n",
      "hours_per_week       0\n",
      "native_country     583\n",
      "earn_over_50k        0\n",
      "dtype: int64\n",
      "/var/folders/_2/sdzrwz45427b53fcr8rggplm0000gq/T/ipykernel_23078/896542310.py:21: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df = df.replace('?', pd.np.nan)\n",
      "INFO:root:Nan values: age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education_num        0\n",
      "marital_status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital_gain         0\n",
      "capital_loss         0\n",
      "hours_per_week       0\n",
      "native_country     583\n",
      "earn_over_50k        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def basic_cleaning(df):\n",
    "    '''\n",
    "    Basic cleaning of data-\n",
    "    '''\n",
    "    #fixing column names:\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "    logging.info(f'Columns: {df.columns}')\n",
    "\n",
    "    #filter categorical columns and numerical columns:\n",
    "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    num_cols = df.select_dtypes(exclude='object').columns.tolist()\n",
    "    logging.info(f'Categorical columns: {cat_cols}')\n",
    "    logging.info(f'Numerical columns: {num_cols}')\n",
    "    \n",
    "     #replacing spaces & - with underscore in categorical columns:\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "\n",
    "    #replacing ? with nan:\n",
    "    logging.info(f'Before replacing ? with nan: {df.isin([\"?\"]).sum()}')\n",
    "    df = df.replace('?', pd.np.nan)\n",
    "    logging.info(f'Nan values: {df.isna().sum()}')\n",
    "\n",
    "    #fill nan with mode for categorical columns:\n",
    "    for col in cat_cols:\n",
    "        if col != 'earn_over_50k':\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            cat_cols.remove(col)\n",
    "\n",
    "    #fill nan with mean for numerical columns:\n",
    "    for col in num_cols:\n",
    "        if col != 'earn_over_50k':\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        else:\n",
    "            num_cols.remove(col)\n",
    "\n",
    "    return df, cat_cols + num_cols\n",
    "\n",
    "train, cols = basic_cleaning(df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eff7cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b57548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e00bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training model on Columns: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country', 'age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
      "INFO:root:Fold: 0\n",
      "INFO:root:Fold: 0, Score: 0.6054567805126353\n",
      "INFO:root:Fold: 1\n",
      "INFO:root:Fold: 1, Score: 0.5685005439845257\n",
      "INFO:root:Fold: 2\n",
      "INFO:root:Fold: 2, Score: 0.5731820109718645\n",
      "INFO:root:Fold: 3\n",
      "INFO:root:Fold: 3, Score: 0.6043548070771081\n",
      "INFO:root:Fold: 4\n",
      "INFO:root:Fold: 4, Score: 0.58933937652731\n",
      "INFO:root:Mean Score: 0.5881667038146887\n"
     ]
    }
   ],
   "source": [
    "def train_model(df_train, cols):\n",
    "    '''\n",
    "    Trains model on train data\n",
    "    '''\n",
    "    logging.info(f'Training model on Columns: {cols}')\n",
    "    \n",
    "    #Initialize KFold:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    fold = 0\n",
    "    for train_index, val_index in kf.split(df_train):\n",
    "        logging.info(f'Fold: {fold}')\n",
    "\n",
    "        #create train dict:\n",
    "        train_dict = df_train[cols].iloc[train_index].to_dict(orient='records')\n",
    "        \n",
    "        #create val dict:\n",
    "        val_dict = df_train[cols].iloc[val_index].to_dict(orient='records')\n",
    "        \n",
    "        #create train target:\n",
    "        train_target = df_train['earn_over_50k'].iloc[train_index]\n",
    "\n",
    "        #create val target:\n",
    "        val_target = df_train['earn_over_50k'].iloc[val_index]\n",
    "\n",
    "        #initialize DictVectorizer:\n",
    "        dv = DictVectorizer(sparse=False)\n",
    "\n",
    "        #fit DictVectorizer on train dict:\n",
    "        dv.fit(train_dict)\n",
    "\n",
    "        #transform train dict:\n",
    "        X_train = dv.transform(train_dict)\n",
    "\n",
    "        #transform val dict:\n",
    "        X_val = dv.transform(val_dict)\n",
    "\n",
    "        #initialize & fit LogisticRegression:\n",
    "        model = LogisticRegression(solver='liblinear', C=1.0, random_state=42)\n",
    "        model.fit(X_train, train_target)\n",
    "\n",
    "        #predict on val data:\n",
    "        y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        #calculate roc_auc_score:\n",
    "        score = roc_auc_score(val_target, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "        logging.info(f'Fold: {fold}, Score: {score}')\n",
    "        fold += 1\n",
    "\n",
    "    logging.info(f'Mean Score: {np.mean(scores)}')\n",
    "\n",
    "    return dv, model\n",
    "\n",
    "dv, model = train_model(train, cols)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c69d2b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "dv = DictVectorizer()\n",
    "train_dict = train[cols].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "y_train = train.earn_over_50k.values\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46a37397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5478402179858726"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_single(sample_dict, dv, model):\n",
    "    '''\n",
    "    Predicts on single row of test data\n",
    "    Sample input:\n",
    "    {   'workclass': 'state_gov',\n",
    "        'education': 'bachelors',\n",
    "        'marital_status': 'never_married',\n",
    "        'occupation': 'adm_clerical',\n",
    "        'relationship': 'not_in_family',\n",
    "        'race': 'white',\n",
    "        'sex': 'male',\n",
    "        'native_country': 'united_states',\n",
    "        'age': 39,\n",
    "        'fnlwgt': 77516,\n",
    "        'education_num': 13,\n",
    "        'capital_gain': 2174,\n",
    "        'capital_loss': 0,\n",
    "        'hours_per_week': 40\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    #transform test dict:\n",
    "    X_test = dv.transform(sample_dict)\n",
    "\n",
    "    #predict on test data:\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return y_pred[0]\n",
    "\n",
    "sample_dict = {     'workclass': 'state_gov',\n",
    "                    'education': 'bachelors',\n",
    "                    'marital_status': 'never_married',\n",
    "                    'occupation': 'adm_clerical',\n",
    "                    'relationship': 'not_in_family',\n",
    "                    'race': 'white',\n",
    "                    'sex': 'male',\n",
    "                    'native_country': 'united_states',\n",
    "                    'age': 39,\n",
    "                    'fnlwgt': 77516,\n",
    "                    'education_num': 13,\n",
    "                    'capital_gain': 2174,\n",
    "                    'capital_loss': 0,\n",
    "                    'hours_per_week': 40\n",
    "                }\n",
    "\n",
    "predict_single(sample_dict, dv, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "224f331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Columns: Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'earn_over_50k'],\n",
      "      dtype='object')\n",
      "INFO:root:Categorical columns: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "INFO:root:Numerical columns: ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week', 'earn_over_50k']\n",
      "INFO:root:Before replacing ? with nan: age                 0\n",
      "workclass         963\n",
      "fnlwgt              0\n",
      "education           0\n",
      "education_num       0\n",
      "marital_status      0\n",
      "occupation        966\n",
      "relationship        0\n",
      "race                0\n",
      "sex                 0\n",
      "capital_gain        0\n",
      "capital_loss        0\n",
      "hours_per_week      0\n",
      "native_country    274\n",
      "earn_over_50k       0\n",
      "dtype: int64\n",
      "/var/folders/_2/sdzrwz45427b53fcr8rggplm0000gq/T/ipykernel_23078/896542310.py:21: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df = df.replace('?', pd.np.nan)\n",
      "INFO:root:Nan values: age                 0\n",
      "workclass         963\n",
      "fnlwgt              0\n",
      "education           0\n",
      "education_num       0\n",
      "marital_status      0\n",
      "occupation        966\n",
      "relationship        0\n",
      "race                0\n",
      "sex                 0\n",
      "capital_gain        0\n",
      "capital_loss        0\n",
      "hours_per_week      0\n",
      "native_country    274\n",
      "earn_over_50k       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test, cols = basic_cleaning(df_test)\n",
    "\n",
    "def predict_batch(df_test, dv, model, cols):\n",
    "    '''\n",
    "    Predicts on test data\n",
    "    '''\n",
    "    #create test dict:\n",
    "    test_dict = df_test[cols].to_dict(orient='records')\n",
    "\n",
    "    #transform test dict:\n",
    "    X_test = dv.transform(test_dict)\n",
    "    X_test[0]\n",
    "\n",
    "    #predict on test data:\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred = predict_batch(test, dv, model, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2b51ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Score on test data: 0.6196447109995377\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'Score on test data: {roc_auc_score(df_test.earn_over_50k, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "796cd811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>earn_over_50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass  fnlwgt      education  education-num  \\\n",
       "0       25        Private  226802           11th              7   \n",
       "1       38        Private   89814        HS-grad              9   \n",
       "2       28      Local-gov  336951     Assoc-acdm             12   \n",
       "3       44        Private  160323   Some-college             10   \n",
       "4       18              ?  103497   Some-college             10   \n",
       "...    ...            ...     ...            ...            ...   \n",
       "16276   39        Private  215419      Bachelors             13   \n",
       "16277   64              ?  321403        HS-grad              9   \n",
       "16278   38        Private  374983      Bachelors             13   \n",
       "16279   44        Private   83891      Bachelors             13   \n",
       "16280   35   Self-emp-inc  182148      Bachelors             13   \n",
       "\n",
       "            marital-status          occupation     relationship  \\\n",
       "0            Never-married   Machine-op-inspct        Own-child   \n",
       "1       Married-civ-spouse     Farming-fishing          Husband   \n",
       "2       Married-civ-spouse     Protective-serv          Husband   \n",
       "3       Married-civ-spouse   Machine-op-inspct          Husband   \n",
       "4            Never-married                   ?        Own-child   \n",
       "...                    ...                 ...              ...   \n",
       "16276             Divorced      Prof-specialty    Not-in-family   \n",
       "16277              Widowed                   ?   Other-relative   \n",
       "16278   Married-civ-spouse      Prof-specialty          Husband   \n",
       "16279             Divorced        Adm-clerical        Own-child   \n",
       "16280   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital-gain  capital-loss  \\\n",
       "0                    Black     Male             0             0   \n",
       "1                    White     Male             0             0   \n",
       "2                    White     Male             0             0   \n",
       "3                    Black     Male          7688             0   \n",
       "4                    White   Female             0             0   \n",
       "...                    ...      ...           ...           ...   \n",
       "16276                White   Female             0             0   \n",
       "16277                Black     Male             0             0   \n",
       "16278                White     Male             0             0   \n",
       "16279   Asian-Pac-Islander     Male          5455             0   \n",
       "16280                White     Male             0             0   \n",
       "\n",
       "       hours-per-week  native-country  earn_over_50k  \n",
       "0                  40   United-States              0  \n",
       "1                  50   United-States              0  \n",
       "2                  40   United-States              1  \n",
       "3                  40   United-States              1  \n",
       "4                  30   United-States              0  \n",
       "...               ...             ...            ...  \n",
       "16276              36   United-States              0  \n",
       "16277              40   United-States              0  \n",
       "16278              50   United-States              0  \n",
       "16279              40   United-States              0  \n",
       "16280              60   United-States              1  \n",
       "\n",
       "[16281 rows x 15 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9250089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(dv, model, model_path):\n",
    "    '''\n",
    "    Save model to model_path\n",
    "    '''\n",
    "    #save DictVectorizer:\n",
    "    with open(f'{model_path}/dv.bin', 'wb') as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "        f_out.close()\n",
    "    logging.info(f'DictVectorizer saved')\n",
    "\n",
    "    #save model:\n",
    "    with open(f'{model_path}/model1.bin', 'wb') as f_out:\n",
    "        pickle.dump(model, f_out)\n",
    "        f_out.close()\n",
    "    logging.info(f'Model saved')\n",
    "\n",
    "def predict(df_test, dv, model, cols):\n",
    "    '''\n",
    "    Predicts on test data\n",
    "    '''\n",
    "    #create test dict:\n",
    "    test_dict = df_test[cols].to_dict(orient='records')\n",
    "\n",
    "    #transform test dict:\n",
    "    X_test = dv.transform(test_dict)\n",
    "\n",
    "    #predict on test data:\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #load data:\n",
    "    df_train, df_test = load_data('./data')\n",
    "    #clean data:\n",
    "    df_train, cols = basic_cleaning(df_train)\n",
    "    df_test, _ = basic_cleaning(df_test)\n",
    "    logging.info(f'Train data shape: {df_train.shape}')\n",
    "\n",
    "    #train model:\n",
    "    dv, model = train_model(df_train, cols)\n",
    "\n",
    "    #predict on test data:\n",
    "    y_pred = predict(df_test, dv, model, cols)\n",
    "    \n",
    "    #save predictions:\n",
    "    df_test['earn_over_50k'] = y_pred\n",
    "    df_test[['earn_over_50k']].to_csv('./data/predictions.csv', index=False)\n",
    "    logging.info(f'Predictions saved')\n",
    "\n",
    "    #save model:\n",
    "    save_model(dv, model, './model')\n",
    "\n",
    "    logging.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966b54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc2a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction_proba': 0.5279585459636567,\n",
       " 'prediction': 1,\n",
       " 'message': 'Income <=50K'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a7a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475b82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a5c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd5150a16d85c014e5d4927b8ac75bae8a55a545327dd7f7547976b47ce2a268"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
